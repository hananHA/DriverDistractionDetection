{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ZYVHEEctAi0h"
   },
   "source": [
    "# Driver Distraction Detection Project\n",
    "## Using Deep Learning and Raspberry Pi\n",
    "(This project is part of the internship program in Wadi Makkah - ML track)\n",
    "\n",
    "### Team members:\n",
    "- Hanan Alharbi\n",
    "- Ahmad Alkaf\n",
    "- Neaam Hariri\n",
    "\n",
    "### Team Mentor: \n",
    "- Sarah Khyyat\n",
    "\n",
    "## Description:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T7SOy0F1Aksc"
   },
   "source": [
    "## Step 1: Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hIiXD-FQAc0n"
   },
   "outputs": [],
   "source": [
    "#import dependencies\n",
    "from collections import OrderedDict\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import datasets\n",
    "from PIL import Image\n",
    "from PIL import ImageFile\n",
    "import matplotlib.pyplot as plt                        \n",
    "%matplotlib inline "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vYTurt0pAnT1"
   },
   "source": [
    "## Step 2: Import Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yE9hsV5SAh1C"
   },
   "outputs": [],
   "source": [
    "data_dir = 'Images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7yLcYLkmsGpt"
   },
   "outputs": [],
   "source": [
    "IMG_SIZE = 224"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VvAB8dZKAuhe"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IxooPWGqAuzW"
   },
   "outputs": [],
   "source": [
    "#data transformations\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomRotation(45),\n",
    "        transforms.RandomResizedCrop(IMG_SIZE),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'valid': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(IMG_SIZE),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], \n",
    "                             [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B-W7XncXAywB"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a6VwOjw5AzBP"
   },
   "outputs": [],
   "source": [
    "train_dataset = datasets.ImageFolder(data_dir + '/train', transform=data_transforms['train'])\n",
    "valid_dataset = datasets.ImageFolder(data_dir + '/valid', transform=data_transforms['valid'])\n",
    "test_dataset = datasets.ImageFolder(data_dir + '/test', transform=data_transforms['test'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u3nxbDOHnGPQ"
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QXoFV-VnnNWw"
   },
   "outputs": [],
   "source": [
    "loaders = {\n",
    "    'train': train_loader,\n",
    "    'valid': valid_loader,\n",
    "    'test': test_loader\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FlGkTpzrDeer"
   },
   "source": [
    "## Step 3: Train Using Transfer Learning (VGG16 - Resenet - DenseNet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "c58mTCImNR_a"
   },
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gp94UMoCozTB"
   },
   "outputs": [],
   "source": [
    "def chooseModel(model):\n",
    "  \n",
    "    if model == 'vgg':\n",
    "        #Load vgg-16 pre-trained model\n",
    "        model_transfer_vgg16 = models.vgg16(pretrained=True)\n",
    "        save_transfer_vgg16 = 'transfer_vgg16'\n",
    "        IMG_SIZE = 224\n",
    "        return model_transfer_vgg16, save_transfer_vgg16\n",
    "  \n",
    "    elif model == 'resnet':\n",
    "        #Load Resenet-50 pre-trained model\n",
    "        model_transfer_resnet50 = models.resnet50(pretrained=True)\n",
    "        save_transfer_resnet50 = 'transfer_resent50'\n",
    "        IMG_SIZE = 229 #224\n",
    "        print('resnet')\n",
    "        # in - 2048\n",
    "        return model_transfer_resnet50, save_transfer_resnet50\n",
    "  \n",
    "    elif model == 'densenet':\n",
    "        #Load DenseNet-161 pre-trained model\n",
    "        model_transfer_densenet = models.densenet161(pretrained=True)\n",
    "        save_transfer_densenet = 'transfer_densenet'\n",
    "        IMG_SIZE = 224 #\n",
    "        print('densenet')\n",
    "        # in - 2208\n",
    "        return model_transfer_densenet, save_transfer_densenet\n",
    "  \n",
    "    else:\n",
    "        return print('The model you chose does not exist')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "N1827rvXDwTT"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nNc3_C7RDyL1"
   },
   "outputs": [],
   "source": [
    "#fine-tune model\n",
    "def fineTuneModel(model, in_features, out_features, dropout):\n",
    "  \n",
    "    model_transfer = model\n",
    "  \n",
    "    # freeze the model parameters\n",
    "    for param in model_transfer.parameters():\n",
    "        param.require_grad = False\n",
    "\n",
    "    # define the classifier layers\n",
    "    classifier = nn.Sequential(OrderedDict([\n",
    "        ('dropout1', nn.Dropout(dropout)),\n",
    "        ('fc1', nn.Linear(in_features, 1000)),\n",
    "        ('relu1', nn.ReLU()),\n",
    "        ('dropout2', nn.Dropout(dropout)),\n",
    "        ('fc2', nn.Linear(1000, out_features)),\n",
    "        ('output', nn.LogSoftmax(dim=1))\n",
    "    ]))\n",
    "  \n",
    "    # update the model classifier\n",
    "    model_transfer.classifier = classifier\n",
    "    \n",
    "    if use_cuda:\n",
    "        model_transfer = model_transfer.cuda()\n",
    "    \n",
    "    return model_transfer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "bY-jpd9DD3WL"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "DyCPDsl_D3iF"
   },
   "outputs": [],
   "source": [
    "# loss and optimizer\n",
    "def lossAndOptimizer(opt, model, lr=0.5):\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    if opt == 'adam':\n",
    "        optimizer = optim.Adam(model.classifier.parameters(), lr)\n",
    "    elif opt == 'SGD':\n",
    "        optimizer = optim.SGD(model.classifier.parameters(), lr)\n",
    "        \n",
    "    return criterion, optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NtoshBc5EDlk"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "neewnsXXEDxD"
   },
   "outputs": [],
   "source": [
    "# load the truncated images to prevent the error OSError: image file is truncated\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "\n",
    "def train(n_epochs, loaders, model, optimizer, criterion, use_cuda, save_path):\n",
    "\n",
    "    # initialize tracker for minimum validation loss\n",
    "    valid_loss_min = np.Inf \n",
    "    \n",
    "    for epoch in range(1, n_epochs+1):\n",
    "        # initialize variables to monitor training and validation loss\n",
    "        train_loss = 0.0\n",
    "        valid_loss = 0.0\n",
    "\n",
    "        # train the model\n",
    "        model.train()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += ((1 / (batch_idx + 1)) * (loss.data - train_loss))\n",
    "          \n",
    "          \n",
    "        # validate the model \n",
    "        model.eval()\n",
    "        for batch_idx, (data, target) in enumerate(loaders['valid']):\n",
    "\n",
    "            if use_cuda:\n",
    "                data, target = data.cuda(), target.cuda()\n",
    "                \n",
    "            # update the average validation loss\n",
    "            output = model(data)\n",
    "            loss = criterion(output, target)\n",
    "            valid_loss += ((1 / (batch_idx + 1)) * (loss.data - valid_loss))\n",
    "\n",
    "            \n",
    "        # print training/validation statistics \n",
    "        print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(\n",
    "            epoch, \n",
    "            train_loss,\n",
    "            valid_loss\n",
    "            ))\n",
    "        \n",
    "        # save the model if validation loss has decreased\n",
    "        if valid_loss < valid_loss_min:\n",
    "            print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(\n",
    "            valid_loss_min,\n",
    "            valid_loss))\n",
    "            torch.save(model.state_dict(), save_path)\n",
    "            valid_loss_min = valid_loss\n",
    "             \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "63y7mUKeEGwG"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u2giA3p0EG8k"
   },
   "outputs": [],
   "source": [
    "def test(loaders, model, criterion, use_cuda):\n",
    "  \n",
    "    test_loss = 0.\n",
    "    correct = 0.\n",
    "    total = 0.\n",
    "\n",
    "    model.eval()\n",
    "    \n",
    "    for batch_idx, (data, target) in enumerate(loaders['test']):\n",
    "        \n",
    "        if use_cuda:\n",
    "            data, target = data.cuda(), target.cuda()\n",
    "            \n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        test_loss = test_loss + ((1 / (batch_idx + 1)) * (loss.data - test_loss))\n",
    "                                                          \n",
    "        # convert output probabilities to predicted class\n",
    "        pred = output.data.max(1, keepdim=True)[1]\n",
    "                                                          \n",
    "        # compare predictions to true label\n",
    "        correct += np.sum(np.squeeze(pred.eq(target.data.view_as(pred))).cpu().numpy())\n",
    "        total += data.size(0)\n",
    "            \n",
    "    print('Test Loss: {:.6f}'.format(test_loss))\n",
    "    print('Test Accuracy: %2d%% (%2d/%2d)' % (100. * correct / total, correct, total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rC_bzjWREJGc"
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Rc74505fEJSG"
   },
   "outputs": [],
   "source": [
    "#define predict function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gq7N4cDClUHD"
   },
   "outputs": [],
   "source": [
    "model, save_path = chooseModel('vgg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = fineTuneModel(model, 25088, 10, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion, optimizer = lossAndOptimizer('adam', model, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = train(3, loaders, model, optimizer, criterion, use_cuda, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(save_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test(loaders, model, criterion, use_cuda)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "DriverDistractionProject.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
